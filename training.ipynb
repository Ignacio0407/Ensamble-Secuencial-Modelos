{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "28089998",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas.api.types import is_string_dtype\n",
        "\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn import clone\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fec5d8a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# DOCUMENTATION CELL\n",
        "SequentialEnsembleDoc = '''\n",
        "    Implements an ensemble of different models to create a meta-model with much better accuracy, though at a higher resource demand. It is similar to Gradient Boosting.\n",
        "\n",
        "    This is achieved by using the same training algorithm (it must be supervised, meaning the expected solution must be known in advance) with different data in each iteration. In this way, model i attempts to compensate for the flaws of model i-1 (the number of models is determined by the n_estimators attribute). This could also be achieved by using different algorithms on the same data, but that was not the case for this project. Furthermore, it can be done sequentially or in parallel, with this project implementing the sequential approach. \n",
        "\n",
        "    The meta-model bases the compensation of each model's flaws on minimizing the gradient of their errors. In this case, the chosen error was the quadratic error. As can be seen, this is an academic project where every decision has been made, and thus many more implementations and combinations can be explored to develop different ensemble algorithms, with this being one potential solution.\n",
        "\n",
        "    The algorithms used to train the data must be **Regressors**, as we need continuous predictions for both classification and regression problems.\n",
        "\n",
        "    Attributes:\n",
        "    -----------\n",
        "    trainingModel : Regressor\n",
        "        The algorithm or regressor used to train the data in each iteration. The performance of the meta-model will be highly determined by this model.\n",
        "\n",
        "    objective : numpy array    \n",
        "        The array possesing the objective variable values.\n",
        "\n",
        "    csv : str\n",
        "        Path to the CSV file to analyze. The target variable must be in the last column.\n",
        "\n",
        "    n_estimators : int : default_value = 15\n",
        "        The number of iterations to be performed. Note that not all of them may be completed due to early stopping. This attribute also impacts the model's performance. More iterations means better accuracy but more excution time.\n",
        "\n",
        "    lr : float : default_value = 0.01\n",
        "        The learning rate, which measures the importance of each individual model's prediction. Typically takes low values between 0 and 1.\n",
        "\n",
        "    sample_size : float : default_value = 0.75\n",
        "        The percentage of data to be used for training. The rest will be used for evaluation via early stopping. Must be between 0 and 1. This attribute also impacts the model's performance. The more data, better accuracy but more execution time.\n",
        "\n",
        "    task_type : str : default_value = 'regression'\n",
        "        The type of task: classification or regression. It should only be set to classification if the target variable is boolean (True, False, 0, 1, Yes, No, etc.). Setting it to classification for a regression task will result in poor accuracy.\n",
        "\n",
        "    early_stopping_patience : int : default_value = 6\n",
        "        The number of iterations the algorithm will accept a model with low importance to the meta-model before halting.  Its function is to reduce execution time without losing accuracy\n",
        "\n",
        "    epsilon : float : default_value = 10^-4\n",
        "        The acceptance value for a model to be considered irrelevant. It is the evaluation score of model i minus the evaluation score of model i-1. Its function is to reduce execution time without losing accuracy\n",
        "\n",
        "    normalization : bool : default_value = False\n",
        "        Defines wether the data should be normalized or not. If some like Knn are not normalized, they will yield poor results.\n",
        "        \n",
        "    Methods:\n",
        "    --------\n",
        "    fit(self, X, y):\n",
        "        Trains the model using the provided training data (X) and objective variable (y) and adjusts the meta-model. Please note they are arrays of the same size.\n",
        "\n",
        "    predict(self, X):\n",
        "        Makes predictions using the trained meta-model. It receives X only because y is stored in self.objective.\n",
        "\n",
        "    Example:\n",
        "    --------\n",
        "    >>> model = SecuencialEnsemble(trainingModel=SomeRegressor(), csv='data.csv', n_estimators=100, lr=0.1)\n",
        "    >>> model.fit(X_train, y_train)\n",
        "    >>> predictions = model.predict(X_test)\n",
        "\n",
        "    >>> cross_val_score(SequentialEnsemble(trainingModel=DecisionTreeRegressor(max_depth=5),objective=individual_objective,lr=0.05, n_estimators=200), original_data,individual_objective,scoring=\"r2\",cv=10, n_jobs=-1)\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73dee9c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# De los csv solo deben convertirse las variables categóricas (texto) a numéricas, usando el método que considere más adecuado.\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6c4e5556",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Step 1: Initialize initial predictions (pred_0) \\n\\n# Step 2: Iterate through all estimators\\n    # 1. Compute residuals (error between true values and current predictions)\\n    remainder_i = y - actual_pred  \\n    # 2. Train a new model (estimator_i) to predict remainders\\n    estimator_i.fit(X, remainder_i)  \\n    # 3. Get predictions from the new model\\n    pred_i = estimator_i.predict(X)  \\n    # 4. Update predictions with learning rate (lr)\\n    actual_pred = actual_pred + lr * pred_i\\n    # 5. OPTIONAL -> Early Stopping\\n    obtain a specified % of the 80% of the original data which was used in step 2 (training) and use the leftover to evaluate and the % to ¿re-train?\\n\\n# Step 3: Return all trained models\\n'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# Step 1: Initialize initial predictions (pred_0) \n",
        "\n",
        "# Step 2: Iterate through all estimators\n",
        "    # 1. Compute residuals (error between true values and current predictions)\n",
        "    remainder_i = y - actual_pred  \n",
        "    # 2. Train a new model (estimator_i) to predict remainders\n",
        "    estimator_i.fit(X, remainder_i)  \n",
        "    # 3. Get predictions from the new model\n",
        "    pred_i = estimator_i.predict(X)  \n",
        "    # 4. Update predictions with learning rate (lr)\n",
        "    actual_pred = actual_pred + lr * pred_i\n",
        "    # 5. OPTIONAL -> Early Stopping\n",
        "    obtain a specified % of the 80% of the original data which was used in step 2 (training) and use the leftover to evaluate and the % to ¿re-train?\n",
        "\n",
        "# Step 3: Return all trained models\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ed30bb56",
      "metadata": {},
      "outputs": [],
      "source": [
        "def transform_csv(csv:str, normalization: bool = False) -> DataFrame:\n",
        "    '''\n",
        "    Objective variable must be at the end! Reads a csv and encodes the string values with an sklearn's OrdinalEncoder, excluding the last column.\n",
        "    '''\n",
        "    data = pd.read_csv(csv)\n",
        "    dicrete_atributes = []\n",
        "    continous_atributes = []\n",
        "    discrete_atributes_encoder = OrdinalEncoder()\n",
        "    for column_name in data.columns:\n",
        "        if (is_string_dtype(data[column_name])):\n",
        "            dicrete_atributes.append(column_name)\n",
        "        else:\n",
        "            continous_atributes.append(column_name)\n",
        "    atributes = data.iloc[:, 0:-1]\n",
        "    discrete_atributes_encoder.fit(atributes[dicrete_atributes])\n",
        "    atributes[dicrete_atributes] = discrete_atributes_encoder.transform(atributes[dicrete_atributes])\n",
        "    if normalization:\n",
        "        atributes = StandardScaler().fit_transform(atributes)\n",
        "    \n",
        "    return (atributes,data.iloc[:, -1])\n",
        "\n",
        "class SequentialEnsemble(BaseEstimator, RegressorMixin):\n",
        "    ''' Documentation can be read through help(SequentialEnsemble)'''\n",
        "    __doc__ = SequentialEnsembleDoc \n",
        "\n",
        "    def __init__(self, trainingModel,objective,n_estimators:int = 15, lr:float = 0.01, sample_size:float = 0.75, early_stopping_patience: int = 6, epsilon:float = 2*10**(-4), task_type: str = \"regression\") -> None:  \n",
        "        self.models = []\n",
        "        self.trainingModel = trainingModel  \n",
        "        self.objective = objective\n",
        "        self.n_estimators = n_estimators\n",
        "        self.lr = lr # regulates the importance of each model's prediction\n",
        "        self.sample_size = sample_size\n",
        "        self.epsilon = epsilon\n",
        "        self.early_stopping_patience = early_stopping_patience\n",
        "        self.scaler = None\n",
        "        self.task_type = task_type\n",
        "        self.mean = np.mean(self.objective)\n",
        "       \n",
        "\n",
        "    def fit(self, X, y) -> None: # I pass the attributes to keep cross_val_score format  \n",
        "        pred_actual = np.mean(y) * np.ones(len(y))\n",
        "        last_r2 = 0\n",
        "        for i in range(self.n_estimators):\n",
        "            # 1. Calculate remainder (gradient of the error (cuadratic here) of all models (pred_actual defines the prediction of all models until i))  \n",
        "            remainder = y - pred_actual \n",
        "            # 0. Random sampling -> Check idx explanations\n",
        "            n_samples = int(len(X) * self.sample_size)\n",
        "            idx = np.random.choice(len(X), n_samples, replace=False)\n",
        "            X_sample = X[idx]\n",
        "            remainder_sample = remainder[idx]\n",
        "            # 2. Train base model\n",
        "            if callable(self.trainingModel):  # A function to create the neural network\n",
        "                input_shape = X_sample.shape[1]\n",
        "                model = self.trainingModel(input_shape)  # Create a new network in each iteration\n",
        "            else:\n",
        "                model = clone(self.trainingModel) # clone to be able to save each trained model. If self.trainingModel were to be directly trained (using fit) it would keep being constantly overwritten (thus overwriting the models saved in self.models), since we would be modifying the reference to the object, not creating a new one.\n",
        "            model.fit(X_sample, remainder_sample)\n",
        "            # 3. Update predictions  \n",
        "            pred_actual[idx] += self.lr * model.predict(X_sample).flatten()\n",
        "            # # 5. EARLY STOPPING\n",
        "            val_idx = np.setdiff1d(np.arange(len(X)), idx) # Data discarded for training is used in validation\n",
        "            actual_r2 = self.early_stopping(X, y, val_idx, last_r2)\n",
        "            if (self.early_stopping_patience == 0):\n",
        "                break\n",
        "            last_r2 = actual_r2\n",
        "            # 6. Save model  \n",
        "            self.models.append(model)\n",
        "    \n",
        "    def early_stopping(self, X, y, val_idx, last_r2:float) -> float:\n",
        "        if len(val_idx) > 0:\n",
        "                val_pred = self.predict(X[val_idx])\n",
        "                val_true = y[val_idx]\n",
        "                actual_r2 = r2_score(val_true, val_pred)\n",
        "        if(abs(last_r2-actual_r2)<=self.epsilon):\n",
        "            self.early_stopping_patience -=1\n",
        "        return actual_r2\n",
        "\n",
        "    def predict(self, X) -> float:\n",
        "        '''\n",
        "        Returns the prediction of the previously trained (fit) meta-model for an objective variable of a given data file compatible with pandas.\n",
        "        ''' \n",
        "        pred = self.mean * np.ones(len(X))\n",
        "        for model in self.models:\n",
        "            pred += self.lr * model.predict(X)\n",
        "        if self.task_type == \"classification\":\n",
        "        # Sigmoide to escalate to [0, 1] for classification tasks.\n",
        "            pred = 1 / (1 + np.exp(-pred))  \n",
        "            pred = (pred >= 0.5).astype(int)\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "36e1fdbf",
      "metadata": {},
      "outputs": [],
      "source": [
        "original_data, individual_objective = transform_csv(\"csv/house_prices.csv\")\n",
        "original_data, individual_objective = transform_csv(\"csv/house_prices.csv\")\n",
        "original_data, individual_objective = original_data.to_numpy(), individual_objective.to_numpy()\n",
        "\n",
        "original_data_normalized, objective_data_normalized = transform_csv(\"csv/house_prices.csv\", normalization=True) #The objective is not normalized, this name is to associate it to original_data_normalized\n",
        "objective_data_normalized = objective_data_normalized.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19d3c9a8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'early_stopping_patience': 6,\n",
              " 'epsilon': 0.0002,\n",
              " 'lr': 0.05,\n",
              " 'n_estimators': 90,\n",
              " 'normalization': False,\n",
              " 'objective': array([25.011, 32.   , 39.674, ..., 39.088, 15.004, 38.428]),\n",
              " 'sample_size': 0.75,\n",
              " 'task_type': 'regression',\n",
              " 'trainingModel__ccp_alpha': 0.0,\n",
              " 'trainingModel__criterion': 'squared_error',\n",
              " 'trainingModel__max_depth': 10,\n",
              " 'trainingModel__max_features': None,\n",
              " 'trainingModel__max_leaf_nodes': None,\n",
              " 'trainingModel__min_impurity_decrease': 0.0,\n",
              " 'trainingModel__min_samples_leaf': 1,\n",
              " 'trainingModel__min_samples_split': 2,\n",
              " 'trainingModel__min_weight_fraction_leaf': 0.0,\n",
              " 'trainingModel__monotonic_cst': None,\n",
              " 'trainingModel__random_state': 357823,\n",
              " 'trainingModel__splitter': 'best',\n",
              " 'trainingModel': DecisionTreeRegressor(max_depth=10, random_state=357823)}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model =SequentialEnsemble(trainingModel=DecisionTreeRegressor(max_depth=5,random_state=SEED),objective=individual_objective,lr=0.05, n_estimators=90)\n",
        "model.set_params(trainingModel__max_depth=10)\n",
        "model.get_params()\n",
        "#Añadir estos tipos de parametros a la rejilla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04ec650e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1320 candidates, totalling 6600 fits\n",
            "Best params: {'lr': np.float64(0.09), 'n_estimators': 250, 'sample_size': np.float64(0.9), 'trainingModel__max_depth': 6}\n",
            "Best R²: 0.9250444957125838\n"
          ]
        }
      ],
      "source": [
        "param_grid = {'lr': [round(i, 2) for i in np.arange(0.01, 0.21, 0.02)], 'n_estimators': list(range(50, 301, 25)), 'trainingModel__max_depth':range(3,7), 'sample_size':[round(i, 2) for i in np.arange(0.75, 0.91, 0.075)] }\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=SequentialEnsemble(trainingModel=DecisionTreeRegressor(random_state=SEED), objective=individual_objective),\n",
        "    param_grid=param_grid,scoring='r2',cv=5,n_jobs=-1,verbose=1)\n",
        "\n",
        "grid.fit(original_data, individual_objective)\n",
        "results = pd.DataFrame(grid.cv_results_)\n",
        "results[['params', 'mean_test_score', 'rank_test_score']].to_csv(\"test/tree_results.csv\", index=False)\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "print(\"Best R²:\", grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "139f9411",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1320 candidates, totalling 6600 fits\n",
            "Best params: {'lr': np.float64(0.15), 'n_estimators': 100, 'sample_size': np.float64(0.9), 'trainingModel__max_depth': 5}\n",
            "Best R²: 0.7658994907349611\n"
          ]
        }
      ],
      "source": [
        "param_grid = {'lr': [round(i, 2) for i in np.arange(0.01, 0.21, 0.02)], 'n_estimators': list(range(50, 301, 25)), 'trainingModel__max_depth':range(3,7), 'sample_size':[round(i, 2) for i in np.arange(0.75, 0.91, 0.075)] }\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=SequentialEnsemble(trainingModel=DecisionTreeRegressor(random_state=SEED), objective=individual_objective),\n",
        "    param_grid=param_grid,scoring='r2',cv=5,n_jobs=-1,verbose=1)\n",
        "\n",
        "grid.fit(original_data, individual_objective)\n",
        "results = pd.DataFrame(grid.cv_results_)\n",
        "results[['params', 'mean_test_score', 'rank_test_score']].to_csv(\"test/tree_results_houses.csv\", index=False)\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "print(\"Best R²:\", grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86dabaa8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
            "Mejores parámetros: {'lr': np.float64(0.01), 'n_estimators': 150, 'trainingModel__metric': 'manhattan', 'trainingModel__n_neighbors': 4}\n",
            "Mejor R²: 0.5578239421982146\n"
          ]
        }
      ],
      "source": [
        "param_grid = {'lr': [round(i, 2) for i in np.arange(0.01, 0.21, 0.04)], 'n_estimators': list(range(100, 301, 50)), 'trainingModel__n_neighbors':range(1,5), 'trainingModel__metric': ['euclidean','manhattan','minkowski']}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=SequentialEnsemble(trainingModel=KNeighborsRegressor(n_neighbors=5, metric='euclidean',n_jobs=-1, random_state=SEED), objective=objective_data_normalized),\n",
        "    param_grid=param_grid,scoring='r2',cv=5,n_jobs=-1,verbose=1)\n",
        "\n",
        "grid.fit(original_data_normalized, objective_data_normalized)\n",
        "results = pd.DataFrame(grid.cv_results_)\n",
        "results[['params', 'mean_test_score', 'rank_test_score']].to_csv(\"test/knn_results.csv\", index=False)\n",
        "print(\"Mejores parámetros:\", grid.best_params_)\n",
        "print(\"Mejor R²:\", grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47ca164b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 750 candidates, totalling 3750 fits\n",
            "Mejores parámetros: {'lr': np.float64(0.01), 'n_estimators': 200, 'sample_size': np.float64(0.75), 'trainingModel__metric': 'manhattan', 'trainingModel__n_neighbors': 2}\n",
            "Mejor R²: 0.7473178400234269\n"
          ]
        }
      ],
      "source": [
        "param_grid = {'lr': [round(i, 2) for i in np.arange(0.01, 0.21, 0.02)], 'n_estimators': list(range(100, 301, 50)), \n",
        "              'trainingModel__n_neighbors':range(1,6), 'trainingModel__metric': ['euclidean','manhattan','minkowski'],\n",
        "              'sample_size':[round(i, 2) for i in np.arange(0.75, 0.92, 0.2)]}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=SequentialEnsemble(trainingModel=KNeighborsRegressor(n_neighbors=5, metric='euclidean',n_jobs=-1, random_state=SEED), objective=objective_data_normalized),\n",
        "    param_grid=param_grid,scoring='r2',cv=5,n_jobs=-1,verbose=1)\n",
        "\n",
        "grid.fit(original_data_normalized, objective_data_normalized)\n",
        "results = pd.DataFrame(grid.cv_results_)\n",
        "results[['params', 'mean_test_score', 'rank_test_score']].to_csv(\"test/knn_houses_results.csv\", index=False)\n",
        "print(\"Mejores parámetros:\", grid.best_params_)\n",
        "print(\"Mejor R²:\", grid.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30fdc0cc",
      "metadata": {},
      "source": [
        "## OLD TESTING CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a3d102a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8906086430977187\n",
            "[0.90805757 0.90883688 0.88716325 0.88485569 0.85877904 0.88157923\n",
            " 0.89277301 0.90657009 0.88689478 0.89057691]\n"
          ]
        }
      ],
      "source": [
        "res = cross_val_score(SequentialEnsemble(trainingModel=DecisionTreeRegressor(max_depth=6,random_state=SEED),objective=individual_objective,lr=0.05, n_estimators=200),original_data,individual_objective,scoring=\"r2\",cv=10, n_jobs=-1)\n",
        "print(np.mean(res))\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ed7a281",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5440459488610172\n",
            "[0.50043453 0.6484962  0.50811438 0.58651223 0.52509013 0.45134701\n",
            " 0.59899397 0.57037598 0.52408828 0.52700677]\n"
          ]
        }
      ],
      "source": [
        "res = cross_val_score(SequentialEnsemble(trainingModel=KNeighborsRegressor(n_neighbors=4, metric='manhattan', weights='distance', random_state=SEED),n_estimators = 150,lr=0.01,objective=individual_objective,sample_size=0.9),original_data_normalized,individual_objective,scoring=\"r2\",cv=5, n_jobs=-1)\n",
        "print(np.mean(res))\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfd3ef08",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9233852314527965\n",
            "[0.93968816 0.93757149 0.9148591  0.91572482 0.89584778 0.92318355\n",
            " 0.92787011 0.92685453 0.93046937 0.92178341]\n"
          ]
        }
      ],
      "source": [
        "res = cross_val_score(SequentialEnsemble(trainingModel=GradientBoostingRegressor(max_depth=5, random_state=SEED),objective=individual_objective,lr=0.05, n_estimators=50),original_data,individual_objective,scoring=\"r2\",cv=10, n_jobs=-1)\n",
        "print(np.mean(res))\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cac6f604",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.06967745237753957\n",
            "[0.07574769 0.07664559 0.05590779 0.07097361 0.07250447 0.06736902\n",
            " 0.07393766 0.07638866 0.04987197 0.07742807]\n"
          ]
        }
      ],
      "source": [
        "res = cross_val_score(SequentialEnsemble(trainingModel=HistGradientBoostingRegressor(max_depth=5, random_state=SEED),objective=individual_objective,lr=0.05, n_estimators=1),original_data,individual_objective,scoring=\"r2\",cv=10, n_jobs=-1)\n",
        "print(np.mean(res))\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c85e691",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.11965824227046191\n",
            "[ 0.23730229  0.18918388  0.17270032  0.21708655 -0.10377557  0.0426274\n",
            "  0.111561    0.2029627   0.08060447  0.04632938]\n"
          ]
        }
      ],
      "source": [
        "res = cross_val_score(SequentialEnsemble(trainingModel=LinearRegression(random_state=SEED),objective=individual_objective,lr=0.05, n_estimators=200),original_data,individual_objective,scoring=\"r2\",cv=10, n_jobs=-1)\n",
        "print(np.mean(res))\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c43770c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.1262970684937635\n",
            "[0.19712728 0.17128294 0.13593283 0.20394962 0.05053328 0.05437013\n",
            " 0.18902791 0.13823466 0.07969064 0.04282139]\n"
          ]
        }
      ],
      "source": [
        "res = cross_val_score(SequentialEnsemble(trainingModel=BayesianRidge(random_state=SEED),objective=individual_objective,lr=0.06, n_estimators=200),original_data,individual_objective,scoring=\"r2\",cv=10)\n",
        "print(np.mean(res))\n",
        "print(res)\n",
        "# Bad results because it is a linear model, doesn't correct well non linear remainders like the one we are dealing with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41c620cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "res = cross_val_score(SequentialEnsemble(trainingModel=GaussianProcessRegressor(random_state=SEED),objective=individual_objective,lr=0.06, n_estimators=200),original_data,individual_objective,scoring=\"r2\",cv=10, n_jobs=-1)\n",
        "np.mean(res)\n",
        "print(res)\n",
        "# Takes too long because it is not good for ensembles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e1c9469",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R2 =  0.8881963071958137\n"
          ]
        }
      ],
      "source": [
        "ensemble_tree = SequentialEnsemble(\n",
        "    trainingModel=DecisionTreeRegressor(max_depth=3, random_state=SEED), # Avoid overadjustment (memorizing the training data) with small trees\n",
        "    objective=individual_objective,\n",
        "    n_estimators = 200,\n",
        "    lr=0.4,\n",
        ")\n",
        "ensemble_tree.fit(original_data, individual_objective)\n",
        "predicciones = ensemble_tree.predict(X=original_data)\n",
        "print('R2 = ', r2_score(individual_objective,predicciones))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8566422",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_network(input_shape) -> Sequential:\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_shape,)),  # Data input layer\n",
        "        Dense(4, activation='relu'),\n",
        "        Dense(1)  # Linear output for regresion\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model  \n",
        "\n",
        "def create_Regressor_network(input_shape) -> KerasRegressor:\n",
        "# Wrap the network in a Scikit-learn compatible estimator\n",
        "    return KerasRegressor(\n",
        "        model = lambda: create_network(input_shape),\n",
        "        epochs=30,\n",
        "        batch_size=32,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "ensemble_neural_network = SequentialEnsemble(\n",
        "    trainingModel=create_Regressor_network,\n",
        "    objective=individual_objective,\n",
        "    lr=0.05\n",
        ")\n",
        "ensemble_neural_network.fit(original_data,individual_objective)\n",
        "predicciones = ensemble_neural_network.predict(original_data)\n",
        "print(r2_score(individual_objective,predicciones))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd477650",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R2 =  0.14427448642762042\n"
          ]
        }
      ],
      "source": [
        "ensemble_Bayes = SequentialEnsemble(\n",
        "    trainingModel=BayesianRidge(random_state=SEED),\n",
        "    objective=individual_objective,\n",
        "    n_estimators = 200,\n",
        "    lr=0.05\n",
        ")\n",
        "ensemble_Bayes.fit(original_data, individual_objective)\n",
        "predicciones = ensemble_Bayes.predict(original_data)\n",
        "print('R2 = ', r2_score(individual_objective,predicciones))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10f2babf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R2 =  0.9652082136385102\n"
          ]
        }
      ],
      "source": [
        "ensemble_kNN = SequentialEnsemble(\n",
        "    trainingModel=KNeighborsRegressor(n_neighbors=5, weights='distance', random_state=SEED),\n",
        "    n_estimators = 70,\n",
        "    lr=0.05,\n",
        "    normalization=True,\n",
        "    objective=individual_objective\n",
        ")\n",
        "ensemble_kNN.fit(original_data, individual_objective)\n",
        "predicciones = ensemble_kNN.predict(original_data)\n",
        "print('R2 = ', r2_score(individual_objective,predicciones))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81ccbfc9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R2 =  0.9949326068550854\n"
          ]
        }
      ],
      "source": [
        "ensemble_Gaussian = SequentialEnsemble(\n",
        "    trainingModel=GaussianProcessRegressor(random_state=SEED),\n",
        "    n_estimators = 90,\n",
        "    lr=0.05,\n",
        "    objective=individual_objective\n",
        ")\n",
        "ensemble_Gaussian.fit(original_data, individual_objective)\n",
        "predicciones = ensemble_Gaussian.predict(X=original_data)\n",
        "print('R2 = ', r2_score(individual_objective,predicciones))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "26cc4d20",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>...</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>PoolQC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1962</td>\n",
              "      <td>1977.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1914</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>291</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1999</td>\n",
              "      <td>1999.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1948</td>\n",
              "      <td>1948.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20</td>\n",
              "      <td>103</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1950</td>\n",
              "      <td>1950.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>29</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1959</td>\n",
              "      <td>1959.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>80</td>\n",
              "      <td>86</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1934</td>\n",
              "      <td>1939.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1882</td>\n",
              "      <td>1925.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>169</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1953</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>18</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1970</td>\n",
              "      <td>1987.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>85</td>\n",
              "      <td>104</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>560 rows × 37 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     GarageCars  Condition2  YearBuilt  GarageYrBlt  LandContour  \\\n",
              "0             2         2.0       1962       1977.0          3.0   \n",
              "1             0         2.0       1914          0.0          3.0   \n",
              "2             2         2.0       1999       1999.0          3.0   \n",
              "3             1         2.0       1948       1948.0          0.0   \n",
              "4             2         2.0       1950       1950.0          3.0   \n",
              "..          ...         ...        ...          ...          ...   \n",
              "555           1         2.0       1959       1959.0          3.0   \n",
              "556           1         2.0       1934       1939.0          1.0   \n",
              "557           2         2.0       1882       1925.0          3.0   \n",
              "558           1         2.0       1953       1953.0          3.0   \n",
              "559           2         2.0       1970       1987.0          3.0   \n",
              "\n",
              "     LowQualFinSF  HouseStyle  GarageType  MSSubClass  WoodDeckSF  ...  \\\n",
              "0               0         2.0         5.0          20           0  ...   \n",
              "1               0         4.0         6.0          75           0  ...   \n",
              "2               0         2.0         1.0          20           0  ...   \n",
              "3               0         5.0         1.0          20         103  ...   \n",
              "4               0         2.0         5.0          20           0  ...   \n",
              "..            ...         ...         ...         ...         ...  ...   \n",
              "555             0         7.0         1.0          80          86  ...   \n",
              "556             0         5.0         5.0          70           0  ...   \n",
              "557             0         5.0         1.0          70           0  ...   \n",
              "558             0         2.0         1.0          20           0  ...   \n",
              "559             0         6.0         5.0          85         104  ...   \n",
              "\n",
              "     SaleType  MiscVal  BsmtExposure  OpenPorchSF  ExterCond  Fireplaces  \\\n",
              "0         7.0        0           3.0            0        3.0           0   \n",
              "1         7.0        0           3.0          291        3.0           1   \n",
              "2         7.0        0           0.0           35        3.0           0   \n",
              "3         7.0        0           3.0            0        1.0           0   \n",
              "4         7.0        0           3.0           29        3.0           0   \n",
              "..        ...      ...           ...          ...        ...         ...   \n",
              "555       7.0        0           0.0            0        1.0           1   \n",
              "556       7.0        0           3.0            0        3.0           1   \n",
              "557       7.0        0           3.0          169        1.0           1   \n",
              "558       7.0        0           3.0           18        3.0           0   \n",
              "559       7.0        0           0.0            0        1.0           0   \n",
              "\n",
              "     FullBath  BsmtQual  MiscFeature  PoolQC  \n",
              "0           1       3.0          4.0     2.0  \n",
              "1           2       3.0          4.0     2.0  \n",
              "2           2       2.0          4.0     2.0  \n",
              "3           3       3.0          4.0     2.0  \n",
              "4           1       4.0          4.0     2.0  \n",
              "..        ...       ...          ...     ...  \n",
              "555         1       3.0          4.0     2.0  \n",
              "556         1       3.0          4.0     2.0  \n",
              "557         1       3.0          4.0     2.0  \n",
              "558         1       3.0          4.0     2.0  \n",
              "559         1       2.0          4.0     2.0  \n",
              "\n",
              "[560 rows x 37 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transform_csv('csv/house_prices.csv')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53e2f238",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      none\n",
              "1      none\n",
              "2      none\n",
              "3      none\n",
              "4      none\n",
              "       ... \n",
              "555    none\n",
              "556    none\n",
              "557    none\n",
              "558    none\n",
              "559    none\n",
              "Name: PoolQC, Length: 560, dtype: object"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TESTING PLAYGROUND\n",
        "originalData = pd.read_csv('csv/house_prices.csv')\n",
        "#data.iloc[0]\n",
        "#data.iloc[0]['GarageCars']\n",
        "originalData.columns\n",
        "#data.iloc[0,1]\n",
        "#key = data.iloc[0,:1]\n",
        "#key\n",
        "#is_string_dtype(data[data.columns[4]])\n",
        "#is_string_dtype(data[data.columns[4]])\n",
        "#data.columns[0]\n",
        "originalData[\"PoolQC\"]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
