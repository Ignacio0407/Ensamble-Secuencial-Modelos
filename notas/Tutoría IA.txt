Ignacio
------------------------------------

Los regressor son con los que entrenamos cada modelo? -> Sí

El meta-modelo se ejecuta al final con 1 solo modelo y nosotros tenemos que programar el ensamble en sí.

Lo que tenemos que programar es el ensamble en sí, después usamos los csv para entrenarlos y evaluarlos. Dónde dice entrenar un modelo tenemos que llamar al .fit del Regressor.

residuoi es el gradiente, es el error que llevamos hasta el momento actual. 

Mejora adicional -> 25% que sobra usarlo para evaluar

Paralelo explota algunos unas columnas.

Mi conjunto de entrenamiento son los 4 train azules, es mi 100%, cada uno lo enntreno con un 75% de ese 100% (que originalmente era el 75%) y tenemos que probar con el 25% del 75% orignal y me olvido del 25% inicial.

El 25% que me sobra al principio es el que uso para predecir los valores del árbol. 

Función perdida 

Evaluar rendimiento cuadrafo al final -> R2, para cada paso podemos usar el RMSE.

Evaluar 

cross-val-score

Emilio
------------------------------------
Muestreo con reemplazamiento permite repeticiones, el sin reemplazamientos no tiene repeticiones. 
Revisar que no venga activo.

Podemos usar funciones como el cross validate, fit y tal, no podemos usar soluciones ya hechas.

Función objetivo es el residuo, siempre se calcula como la diferencia del valor real menos la predicción.

Con validación cruzada tenemos el 80% para entrenamiento, 
luego con el 75%(o el porcentaje que pasen por parámetro) de ese 80% lo usamos para entrenar y 
el 25%(o el que sea) restante será para el early stopping.
Tras el paso 3.4 del pseudocódigo.


Siempre se entrena con ese 75%(o el que sea), aprovechamos esos datos que sobran para el early stopping. En cada iteración.

En early stopping podemos usar MSE, R^2, error cuadratico, el que queramos.

Para usar el sklearn cross validate habría que heredar BaseStimator y ClassificationMixMix, 
en nuestro caso un Regressor.